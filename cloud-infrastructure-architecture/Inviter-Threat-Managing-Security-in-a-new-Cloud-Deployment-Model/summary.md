# Inviter Threat: Managing Security in a new Cloud Deployment Model

**Video Link**: [Watch on YouTube](https://www.youtube.com/watch?v=ilnOvSV0QtY)

- **Author**: Meg (Alloy)
- **Talk Type**: Security

## Summary

This presentation explores the security challenges and solutions for the "Bring Your Own Cloud" (BYOC) deployment model, where service providers deploy and manage infrastructure within customer-owned cloud environments. The speaker shares practical experiences from implementing BYOC at a fintech startup, covering evaluation criteria, common pitfalls, deployment strategies, and security controls to maintain compliance and security posture.

## Key Points

- BYOC fills gap between API-based SaaS limitations and need for data locality/low latency processing
- Model thrives at intersection of proximity requirements and convenience demands
- Primary use cases include data processing, warehousing, streaming, and ML operations
- Security evaluation requires distinguishing need-to-haves from want-to-haves based on compliance requirements
- Organizational peculiarities can obstruct BYOC deployments and reduce convenience benefits
- Dedicated AWS accounts provide best security boundaries but require careful network and IAM planning
- Service Control Policies, Resource Control Policies, and logging remain critical security controls

## Technical Details

**BYOC Model Overview:**
- Client provides cloud environment, vendor manages resources within that environment
- Fills gap where API-based SaaS cannot meet data locality or latency requirements
- Increasingly popular among early-stage companies as differentiation strategy
- Resources typically include compute, databases, encryption keys, and identity management

**Existing Cloud Deployment Models (Most to Least Work):**
1. **DIY Method**: Vendor provides commands/instructions for manual resource creation
2. **Helper Tools**: Vendor provides modules, zip files, or automation for easier deployment  
3. **API-based SaaS**: No customer infrastructure hosting required, minimal firewall changes

**BYOC Evaluation Framework:**

*Step 1: Need-to-Haves vs Want-to-Haves*
- Identify requirements from client contracts, regulatory compliance, audit programs
- Distinguish actual requirements from internal security preferences
- Compare vendor capabilities against hard requirements
- Example conflict: Static production access restrictions vs. vendor access needs

*Step 2: Organizational Peculiarities Assessment*
- Identify processes and tooling that could obstruct BYOC deployment
- Verify convenience factor retention after addressing peculiarities
- Common issues: AWS Config remediation loops, remote state dependencies, break-glass access patterns

**Common Implementation Challenges:**

*AWS Config Conflicts*:
- Automatic remediation can interfere with vendor-deployed resources
- Solution: Separate monitoring from remediation or use feature flags

*Remote State Dependencies*:
- Infrastructure modules that lookup VPC information from Terraform state
- Problem when vendor deploys into non-managed VPCs
- Solution: Design modules with external resource flexibility

*Break-Glass Access*:
- Tools dependent on customer-managed clusters become unavailable
- Solution: Maintain alternative access methods (EC2-based vs EKS-based)

*Zero Trust Architecture Conflicts*:
- Resource-based controls and VPC endpoint requirements
- Custom networking solutions and internal proxy setups
- Solution: Plan adaptation strategies for networking requirements

**Deployment Strategy Options:**

*1. Half Deployment (Not Recommended)*:
- Vendor handles initial deployment, customer assumes ongoing maintenance
- Combines worst aspects: complexity without convenience
- Still encounters full BYOC roadblocks

*2. Shared VPC Approach*:
- Deploy vendor resources within existing customer AWS account VPC
- Challenges: High-privilege identity requirements, networking exposure risks
- IAM scoping limitations: VPC not available as universal condition key
- Alternative: Use resource tags as global condition key

*3. Dedicated AWS Account (Recommended)*:
- Provision separate AWS account per BYOC vendor
- Benefits: Natural permission boundaries, isolated billing, CSPM separation
- Drawbacks: Data access requirements may break isolation, potential data duplication costs

**Security Controls and Mitigations:**

*Networking Security*:
- Avoid simple IP allowlisting or SSH tunnels
- Prefer PrivateLink integration and resource-based endpoints
- Restrict access to specific vendor accounts and resources only
- Mixed vendor willingness to implement advanced integration options

*Service Control Policies (SCPs)*:
- Most effective when restricting entire services rather than granular permissions
- Requires vendor use of customer-owned identities (not external identities)
- Focus on wholesale service-level restrictions

*Resource Control Policies (RCPs)*:
- Limited AWS service support prevents holistic enforcement
- Useful specific policies: Block external source accounts, restrict external OIDC providers
- Helps prevent confused deputy problems

*Logging and Monitoring*:
- Maintain organization-managed CloudTrail in BYOC accounts
- Develop incident response runbooks for vendor access termination
- Preserve visibility despite reduced control

**Organizational Unit Placement:**
- AWS recommends specific OUs for third-party managed accounts
- No single right answer, requires organizational consideration
- Consider compliance, billing, and management requirements

**Data Access Patterns:**
- Original isolation goals often compromised by data access needs
- Options: Direct data access grants or data duplication to vendor environment
- Balance security isolation against operational complexity and costs

**Key Recommendations:**
- Clearly define hard requirements vs. security preferences
- Audit existing deployment pipelines for BYOC compatibility
- Implement feature flags for configuration flexibility
- Plan networking architecture adaptations in advance
- Maintain comprehensive logging and incident response capabilities
- Design security controls that work with vendor operational needs

**Industry Context:**
- Becoming standard offering for early-stage companies
- Similar to established SaaS model but with infrastructure co-location
- Requires balancing convenience with security and compliance needs
- Different regulatory environments may have varying requirements

## Full Transcript

Hello everyone. Welcome to talk two uh track let's say two uh after a room swap give or take. Uh this is in uh this is inviter threat managing security in a new cloud deployment model by me. Uh couple talks questions before we get started. Uh cell phones on silent questions either on slack or raise your hand and I will bring you the mic so the internet can hear them. Uh and uh I think that's it. Yeah. No other talk. No, no other announcements. Uh, please welcome me. Let's go. Hey everyone, good morning. Really excited to be here for forward cloud sec 2025 and doubly excited to share with you all my experiences on ba balancing security when working with a new cloud deployment strategy. At the end of this session, I hope you leave with an understanding of what this increasingly popular deployment strategy even is. you begin to think about your own requirements for embracing the strategy or not and the mitigations you can establish to maintain security posture and compliance. Quick detour just about myself and to set the stage for the context of the experiences I will be sharing with you today. I'm Meg. If I look familiar, I was here last year. Really excited to be back. Um, I don't typically like to speak too much about my day job, but just for context of where I'm coming from, Alloy is a latestage fintech compliance tech startup based in New York City. The experience I speak from today will be primarily from working at Alloy. So, please keep in mind we may operate in different legal regulatory spaces and have different compliance requirements than your organization does. Additionally, I am an AWSonly specialist, so I'd love to hear how other CSPs interact with this model. Um, and I welcome those comments during Q&A or throughout the conference. So, briefly, what we'll cover today is a level setting of what the bring your own cloud deployment model is and how it differs from existing patterns. We'll talk about the gaps this new model serves and examples where we've seen service providers offering it. Next, the main content will focus on how we personally thought through when to use the strategy and the deployment patterns and practices we use to make it successful. So before diving into bring your own cloud really briefly wanted to talk about how I view the existing cloud deployment models. I had these organized from the green to the white in what would be the most work for your organization and then to the white the least amount of work. So both the green and the purple we have some concept of the vendor or the service provider providing some level of instructions AM permissions etc for how they might need resources configured to support their product. The DIY method just a little bit scrappier maybe they just give you a list of commands to run and your teams have to actually go and run those commands. The purple box we have a little bit less work but same kind of security posture where they might provide uh built-in modules or some sort of helper functionality, zip files, etc. to make the amount of work on your teams easier. And then all the way on the right we have what I'm calling API based SAS. You are all familiar with this, right? You don't host anything for the vendor product. The only amount of infrastructure change you might have to do is changing your firewall rules. Um and other than that the total uh ownership of hosting that product is completely on the vendor and SAS is obviously really convenient right because it is about the most minimum amount of work for your teams. However, there are use cases where API based SAS will not solve for example scenarios where data locality is really important or where high proximity processing are necessary. So enter the bring your own cloud deployment model where the client provides the cloud environment and the service provider takes over some level of management and ongoing maintenance within that cloud environment. As a visual here I have just an example diagram of how we've seen this played out. So on the left we have the purple circle which is someone or a process in your organization will make the cloud environment that big purple box and then the green circles on the top is we have by some process or person the vendor will then take over management of resources within that cloud environment. We've seen various levels of sophistication of the resources that are actually deployed in these cloud environments. Most often they have some level of compute and a database essentially for metadata at a bare minimum. But we've also seen really advanced uh infrastructures deployed where they may have multiple databases, multiple encryption keys, they're managing a high number of identities, etc. And in case this is the first time you're hearing of bring your own cloud, I want to say you aren't uh new. This is quite common. Um, and if you think this is the silliest thing I've ever heard, this is absolutely ridiculous. Who would ever sign up for this? I likewise want to agree that I had a similar sentiment, but we've seen that it's becoming increasingly increasingly popular among early stage um companies as a way to differentiate themselves. And to me, it looks like it's definitely here to stay, at least for a little bit. So where bring your own cloud really thrives is the intersection of two places and that is the need for your services and the vendor services to be hosted in close proximity to each other and convenience. So the need for proximity could be kind of in two buckets. One for legal and compliance reasons you can't let your data leave your environment or for latency issues i.e. it wouldn't make sense or be it would be prohibitive for the data to transfer over the internet or many network interfaces. And second is really to achieve the same level of convenience that typical API based SAS comes with. So some of the product use cases we've seen proposed and we've adopted as a bring your own cloud model have generally fallen under the wider data processing umbrella. So whether that's database or data warehousing solutions, data streaming to copy between data sources and lastly data operations i.e. doing machine learning or data classification on the data elements themselves. So how we determined if this deployment model is right for you? For reasons obvious for folks sitting in this room, although it looks like it could be really convenient to just let someone do cloud for you, um there can be serious detriments in legal and compliance and general security risk to letting a third party have high levels of control over a portion of your cloud environment. So similar to Maslau's hierarchy of needs, we'll start with the most foundational need to haves and then from there start thinking about the other concerns you should be concerned about before adopting this model. So before looking too closely at implementation boundaries, the first step is identifying your organization's need to haves versus your want to haves. That is what are the controls that you attest to in your client contracts with your regulators with your compliance standards, your audit programs, and your published security policies that fundamentally define your need to haves. Of course, your security teams and you all have likely built many layers of internal security standards, requirements that you look for when integrating new architectures or working with new partners. However, at the end of the day, those are likely a little bit different than actually what your true requirements are. And your organization's chosen implementations of those requirements are not actually the requirements themselves. So here we have four examples of both my current organization's general uh requirements and I've also included some generalized statements about requirements from uh common compliance framework to serve as an example. So what you need to do is compare your need to haves against what the service provider intends to do with the bring your own cloud architecture. If you've outlined your requirements and the service provider conflict with those, that's pretty much end of the game, right? The bring your own cloud model likely won't work for you. For example, the second requirement on our list, restrictions on granting long-standing access to production. In my current organization, that meant that we couldn't give persons or processes static permanent access to have uh access to decrypted client data, PII, etc. in production environments. And we had one service provider in particular whose product use case needed to have the ability to query our production data and do data classification on those data elements. So because of that obviously they needed some access uh to that data in order to perform those classification methods. However, the way that they wanted to do bring your own cloud would have also granted a subset of their employees static access to the data the service had access to. So for that use case, we were unable to adopt bring your own cloud because those two statements were irreconcilable. However, for a second service provider with a different use case, they wanted to do data replication and we only wanted to use them for internal only uh metadata-esque data. For us, we were totally fine with adopting bring your own cloud for them even though their bring your own cloud deployment would have also granted their employees and processes the same kind of static level of access to that data. But for us it was classed differently and we weren't crossing into that restriction number two. So moving beyond the can it work, one of the main selling points of this architecture is that it's convenient. It's meant to save your organization time and personnel that can be better spent elsewhere and it's meant to put integrating a new service into the fast lane. And across a given CSP, although organizations will be using the same foundational set of services, each will have their oddities and their special peculiarities of how they deploy, manage, and design their cloud environments. And that's great uh until it's not like now. Unfortunately, these sorts of specialties can cause unforeseen problems in the bring your own cloud model because the service provider typically defines a standard deployment for all clients across the CSP with not a lot of customizations. So, these sets of standard deployments won't match your company's peculiarities. So, it's important to recognize when and where you've made assumptions about these being present. For example, we might automatically assume resources match a certain standard or go through a certain deployment pro process. And the bring your own cloud model, neither of these are going to be true. Therefore, after identifying your absolute must-haves, the next step to evaluating bring your own cloud is identifying the processes, tooling, etc. that compose your own organization's peculiarities that would obstruct a bring your own cloud deployment. essentially verifying that this model will still retain that convenience factor for you. Here are some of the issues our own peculiarities caused when adopting bring your own cloud to hopefully serve as inspiration of how you can preempt them. We typically have AWS config deployed in our cloud environments including remediation and monitoring actions. However, we didn't want the resources deployed by the service provider to end up in endless cycles of remediation. And at the time, we couldn't decouple the remediation from the monitoring aspect. Additionally, we made assumptions that our infrastructure always came through our deployment pipelines. For us, this manifested in several of our key modules having remote state lookups for VPCs. So if we ever tried to deploy resources into a VPC that we did not create, obviously that would cause errors. The last example is a little bit similar to the above is in a few examples we were going to have our service providers deploy EKS clusters as part of their infrastructure. However, we wanted to retain the ability for our internal team members to get access to these EKS clusters for break glass scenarios. But we realized the product we used to enable the cluster access was actually reliant on us managing the cluster. If we were no longer managing the cluster, we had no ability to deploy this product that we use in break glass. So instead, we reverted to using an older and less cost-effective pattern where we hosted our break glass vendor on EC2 instances instead. In all of these scenarios, we made reasonable assumptions at the time we were building. However, the choices we made had implications for the bring your own cloud model we couldn't foresee. If you believe you could adopt bring your own cloud, I suggest you take a look at how you currently deploy your cloud infrastructure. Try to look out for references to remote state or other sorts of external resources. And in a similar vein, I suggest being proactive in creating flags that can turn off or on features and infrastructure components as well. In the first example, it would have been much easier if we could just deploy config only in monitoring mode and not uh remediation mode as well. And for the third example, we were lucky that we had still retained the uh flag for EC2based hosting when EKSbased hosting was no longer an option. And in case you thought that was the end of our issues, I am here to serve one more here to share one more of our near misses. We were in the process of moving to a zero trust architecture and hadn't yet implemented resource-based controls or RCPs to require connections to go through VPC endpoints. But if we had already done that, this was a requirement that likely would have been needed to adapt as well. If you're not in AWS or VPC endpoint shop, this could also present itself as you having a custom networking solution or some kind of internal proxy setup. The main question I hope you take away from this is you start thinking ahead about how these sorts of patterns and practices could be adopted in a bring your own cloud deployment model. And the last example has been left up to the listener and that's you. If you're able to think about a challenge that bring your own cloud would bring to your current deployment strategy, I want to hear it. If you can come up with it before Q&A, that's awesome. But if not, uh, I'll be here for the next few days. So now that I've given you enough problems to think about at night, I want to transition into talking about some deployment strategies and what we ended up going with. So the first deployment strategy is really what I would call a half deployment strategy. And this is where you essentially do bring your own cloud but only for the initial deployment and then you assume ownership over the ongoing maintenance of those resources after deployment. I would strongly recommend against this, although it looks a little bit enticing for a PC uh type of deployment, but the truth is you're still going to encounter whatever roadblocks you would have encountered in a full bring your own cloud model. Um, and additionally, you're essentially signing up your internal teams to manage the ongoing resources. So really, I would view this as a lose-lose in that you're not getting the convenience and you're still going to have problems. The next deployment option is one we didn't personally use was utilizing a VPC within one of our existing AWS accounts. And this to us was something we had originally considered because it's how we deploy current vendor specific tooling. But the biggest challenge with continuing in this pattern in the bring your own cloud world is the service provider typically needs two things. an identity with high levels of permissions and some sort of networking construct to expose databases Kate's clusters for management. Although it's possible to limit networking capabilities to only the target VPC, having those networking components may not align with your risk tolerance. And looking at the abil the options we have for managing the AM side of things. Not all AM resources can be scoped to a VPC and VPC is not a generically available AM condition key even for resources that are allocated to a VPC. Comparatively you could use the AWS resource tag as a global condition key. However, you would need to ensure then that the service provider is adhering to that. Um and while it's technically possible, is it still convenient? Uh that's an open question. Lastly, the uh deployment strategy we did end up going with is the completely fresh environment. I.e. we would vend each bring your own cloud provider their own AWS account for them to completely manage independently. Look, everyone knows the accounts are great. Default permission boundaries, default uh billing and if you use CSPMs or security hub, you can use account levels uh to essentially carve out resources that are owned by the service provider. And this is probably what any salesperson that is trying to sell you a bring your own cloud uh product would tell you to do, right? So I also want to be very clear that there are some negative drawbacks to this option and it's going back to the use cases we talked about before often about data classification etc. So this product will need access to the data to replicate to monitor to classify. So what had originally started as yeah it's totally a completely isolated environment uh can no longer remain completely isolated and serve its original function. The other option you have, of course, is to duplicate your data from your original data source into the environment that the service provider is in. But again, that will have potentially high cost implications and is another thing that your teams have to manage as well. And if that wasn't exciting enough, here's another thing to think about as an exercise. Um, if you choose to grant the service providers an exclusive AWS account, uh, where do you put those? I have highlighted in purple some OUS that might be of interest according to the AWS environment uh white paper. Uh however, I really don't think there is necessarily one right or wrong way to do it. Uh just something to think about. And so moving from problems to solutions, I'd love to share with you some of the mitigating controls we identified and utilize. First to handle the necessity for the networking path into the environment. Most commonly the service providers wanted to achieve this by either allow listing their egress IPs or with an SSH tunnel. However, the silver lining of service providers actually offering a bring your own cloud model is that typically means that they themselves have to have a presence within the CSP. Therefore, to better adhere to zero trust architecture patterns, you could instead pursue something like a private link integration or using resource-based endpoints to restrict access to only those specific accounts and only those specific resources to the service provider. To be clear, we have seen mixed adherence and willingness from service providers to use those advanced integration options, but they are technically available. Second, the usage of service control policies and resource control policies. Obviously, they need high levels of access. And the most efficient use for service control policies in these environments is to restrict access wholesale on the service level rather than trying to carve out groups of permissions. And just a note to be really clear in case um you weren't already aware, if you're going to use service control policies, you need to make sure they're using an identity within your owned account and not their external identity. And lastly, we have the also cool, hot, and flashy uh RCPs. Unfortunately, they aren't uh supported in every AWS service, so they can't be used holistically to enforce configuration standards across all resources. However, some RCPs of note that I would suggest in this environment include a block on using um the source account from being outside of both of your organizations and the vendors attested uh AWS accounts to try to prevent some uh confused deputy problems. And additionally, you could consider adding restrictions on STS to restrict adding external OIDC providers. Last and certainly not least, logging and monitoring. You give up a lot of control in this environment and that is pretty obvious. However, that doesn't mean you have to give up on your visibility. Maintain organization managed cloud trail within your bring your own cloud accounts and maintain a runbook on how to cut off access from the service provider in case of incident response. If you're walking away from this with more questions than answers, that's completely expected. I hope you're leaving with curiosity about your need to haves and your want to haves for your respected organization and industry. After you've identified your requirements, take a look at your current deployment pipelines, CSPM configurations, etc. to understand how bring your own cloud could impact the assumptions you've made and start brainstorming how these can be adapted to make bring your own cloud successful. Lastly, I hope you've learned something from our experiences and our challenges and solutions that you can take to your organizations. And with that, we have some time for a Q&A questions. All right, I'll start with one. Okay. What should you expect from your bring your own cloud vendors in terms of documenting what data they're going to need and what access they're going to need to your environment? Yes. So, typically what I ask for when I'm looking at these service providers is I always look to see that they are being honestly ideally uh publicly listing what the resources they're going to be creating are. Obviously in this environment that won't necessarily stop them from deviating from what they're asking for. Um but what we try to avoid in that kind of situation is um almost like where the vendor is not actually quite sure what they're working on. I.e. they might still be uh building out the infrastructure layer of their product. Um, but we want to be a little bit more sure about actually what they are intending to build before it gets built. And then there was a second part. No, that was it. Okay. Um, I've got one from Slack from Abishek. Uh, how do you figure out remediation and patching strategy for bring your own cloud resources? You know, do you update images, harden ales? If you do that, it might break the functionality, but if you just ask vendors to to patch them, you have no control over turnaround time. Yeah. So, that's a really great question. And how we've really gone about thinking about this is going back to the the need to haves. Um, and although listen, I'm not here to tell you patching is bad. Patching is good, right? Restricting network control is generally a good thing. Um but for us we did have to give up some level of control in that environment. Um and so for us we found like when you try to embrace kind of both the uh they're going to manage it and we're going to manage it. For us it was always um too much effort to do the remediation. So for us the chosen path forward was as long as we can make their I'm sorry microphone people. um their needs align with what our actual need what they need to do align with what our requirements are. We want to give them as much power as possible. Makes sense. Any other room questions? Cool. Got one. Uh what are you doing about um logging of network activity like VPC flow logs and um DNS query logs from the 2 resolver? seems like they would be quite difficult in a bring your own cloud. Yeah. So for us uh at the current moment, just being honest, we don't really um do too much of that. Um just with our current security posture, it's it's been kind of low on the list. So for us, we aren't so concerned with that. Although I do recognize that that it could be a risk. All right. Well, that is going to do us for time on this one. I'm sure Meg has a bunch of time for questions. We'll be around for for birds or feather sessions as well. Um, yeah. Thank you, Mike. Thank you,