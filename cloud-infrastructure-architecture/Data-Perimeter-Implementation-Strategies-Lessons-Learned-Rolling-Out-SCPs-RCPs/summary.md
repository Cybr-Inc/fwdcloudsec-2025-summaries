# Data Perimeter Implementation Strategies: Lessons Learned Rolling Out SCPs/RCPs

**Video Link**: [Watch on YouTube](https://www.youtube.com/watch?v=Pd6rbBjiXaA)

- **Author**: Ben Joyce and Agnel Amodia (Vanguard)
- **Talk Type**: Cloud Architecture

## Summary

This presentation details Vanguard's comprehensive data perimeter implementation across their AWS organization using Service Control Policies (SCPs) and Resource Control Policies (RCPs). The speakers share practical lessons from securing 500+ AWS accounts serving 50 million investors, covering their three-pillar approach (identity, resource, network), implementation challenges, and strategies for developer collaboration. They emphasize the importance of CloudTrail analysis, account-level policy deployment, and automated exception management through CI/CD pipelines.

## Key Points

- Vanguard operates 500+ AWS accounts with 80% of workloads in the cloud, serving 50 million investors with 20,000 employees
- Data perimeter built on three pillars: identity (trusted identities only), resource (environment separation), and network (trusted networks only)
- Applied SCPs and RCPs at account level rather than OU level for greater granular control and flexibility
- No dry-run mode for policies required extensive CloudTrail analysis to predict application impact before deployment
- Developed Python scripts to analyze CloudTrail events and identify potential violations before policy enforcement
- Focused initial network parameter controls on privileged identities (human users, application identities, EC2 roles) before expanding to Lambda functions
- Developer engagement through awareness programs, office hours, and email communications was crucial for smooth rollout
- Hit AWS policy size limits when hardcoding VPC IDs and corporate IP ranges, requiring dynamic Lambda-based solutions

## Technical Details

**Architecture Scale:**
- 500+ AWS accounts across production, non-production, and business domain OUs
- 10,000+ human identities and 16,000+ application identities
- 700+ VPCs with busiest accounts containing 1,000 S3 buckets, 5,000 roles, 10,000+ policies
- SCPs customized per LOB OU based on risk profile and governance needs

**Three-Pillar Control Framework:**
- **Identity Parameter**: RCPs ensure only trusted organization identities can access resources
- **Resource Parameter**: Environment separation (non-prod cannot access prod resources)
- **Network Parameter**: VPC endpoint policies restrict access to trusted networks only

**Implementation Strategy:**
- Account-level policy deployment for granular control vs OU-level for easier management
- CloudTrail analysis using Python scripts to identify cross-account access patterns
- Pre-deployment violation flagging: user identity account â‰  recipient account ID
- Source IP analysis comparing against internal VPC and corporate CIDR ranges
- Phased rollout starting with privileged identities before expanding scope

**Policy Management Challenges:**
- AWS policy size limits hit when hardcoding VPC IDs and IP ranges
- Lambda function solution for dynamic VPC ID fetching and CloudFormation template updates
- Dependency on Lambda function reliability for policy deployment success
- Lack of global condition keys like `aws:VpcId` for organization-wide VPC identification

**Exception Handling:**
- CI/CD pipeline integration with CSPM tools for policy violation detection
- Risk management system integration requiring documented exceptions
- Tag-based exception approach with fallback to account-level exceptions
- S3 bucket challenges: resource tags only work on objects, not buckets
- Principal account condition key used as coarse-grained alternative

**Monitoring and Validation:**
- CloudTrail dashboards for real-time access denial spike monitoring
- Post-rollout developer application certification process
- Automated queries identifying resources with data perimeter tags lacking documented exceptions
- Rollback procedures for large-scale access issues

**Key Condition Keys Used:**
- `aws:PrincipalOrgPath` for identity parameter controls
- `aws:ResourceOrgPath` for resource parameter enforcement
- `aws:SourceIP` for network parameter validation
- `aws:ResourceTag` for exception handling (limited S3 support)
- `aws:PrincipalAccount` as S3 bucket exception workaround

---

## Full Transcript

and uh I will introduce Agnal and Ben and we'll let them introduce the talk. Good afternoon and welcome to this talk on Vanguard's uh data parameter journey. Uh my name is Ben Joyce. Uh I am a IM cloud leader with Vanguard and I'm joined by Agnel Amodia who's our tech lead uh who has been leading and driving our data parameter program. In today's session, we will look at what went into defining our boundaries, our uh implementation plans, uh the strategies that we use for planning and collaborating with uh development teams and other centralized teams. Uh we'll also look at some key challenges we had to overcome uh in terms of AWS limitations and such. and uh we'll take some questions in the end. First, a quick look at uh Vanguard. Vanguard is one of the most respected investment management companies in the world, offering a broad selection of investments, advice, retirement services, and insights to individual investors, institutions, and financial professionals. We adhere to a very simple core purpose to take a stand for all investors to treat them fairly and to give them the best chance for investment success. We just recently celebrated our 50th anniversary. We headquartered in Malvin uh Pennsylvania. We have u uh more than 16 uh global locations spread out across uh North America, Europe, and uh APAC. Uh currently we cater to more than uh 50 million investors uh supported by our 20,000 awesome crew members. Um so that gives uh a sense of the scale the responsibility that we are operating with. So it isn't uh just about protecting our workloads. It's more about preserving the trust and confidence of uh millions of people who trust Vanguard to secure their financial future uh every day. uh a little bit on the lay of the land uh in terms of uh the scale and complexity we are operating with currently more than 80% of our workloads are in the cloud uh most of it in the AWS cloud at a high level our AWS or is uh segmented by environment and um uh business domains uh so what that means is our AWS OUS are logically separated by uh production, non-production and uh specific business domains and our SCPs are applied uh to these LOB specific OUS and they're customuilt uh based on the risk profile and the governance needs for each one of these uh LOB OUS and uh from a scale perspective uh we're talking about 500 plus AWS accounts uh more than 10,000 human identities and 16,000 application identities spread across uh 700 plus VPCs. And then uh some of our busiest AWS accounts uh we're talking about a thousand S3 buckets, 5,000 AWS roles and more than uh 10,000 policies in a single account. Uh moving on. Uh so there is also complexity added uh in terms of how our policies are managed by uh the different teams that manage those policies. Uh we primarily have three uh stakeholder groups. Number one, the centralized uh network and infrastructure team. They own the VPC endpoint policies uh that helps them manage um network access that helps them to bootstrap AWS infrastructure. Uh and uh then comes the uh centralized cloud IM team that Agnil and I are part of. We manage uh the SCPs, RCPs and permission boundaries. Uh so we make sure that we enforce these security invariance and orwide controls uh preventive pipeline checks so that way we can enable new AWS services in a very secure and scalable way. And both of these centralized teams are what uh help us provide a more decentralized approach to our uh development teams uh so that they can focus on uh just granting access to their applications so that they work and they use u resource-based policies and permission policies uh to make that happen. And uh to add to that um not all applications behave the same. Uh production applications have to access uh non-product data and some of our applications need to send data to third party applications, third party vendors for uh regulatory purposes and uh some of our CSPM tools have uh to scan uh the entire AWS org for security findings. So, um, we're talking about, uh, not just layering controls, we're talking about having to, uh, thread a needle, uh, through existing independently managed controls. Uh and moving on to uh how we um built our controls or our control objectives. We uh when we break down AWS to its core pillars, its identities, resources and networks and that's precisely where we applied our controls. Uh we used RCPs to make sure that only trusted identities can uh access our resources. We enforce VPC endpoint policies to ensure that access came only from our approved networks such as our internal VPCs and our corporate cider ranges. By aligning each of these controls uh to a specific component u identity resource and network, we were able to build a parameter that's uh clear, scalable and uh secure by design. And uh it's very important also to define our boundaries before we embark on this implementation journey. Uh for each arg uh it could be different. Um for us it was um it's pretty straightforward but it is uh important to uh kind of go over that quickly as well. Um for resource parimeter what that meant is non-prods cannot access produces and vice versa. And this boundary also prevents any of our orgs principles from having access to uh resources that do not belong to our organization. Uh for network parameter it meant that access to our resources will be allowed only when requests originate from our trusted networks like our VPCs and um our corporate uh cider ranges. uh anything coming from the public uh internet even if it's through a principle uh even if it's through our corporate principle is blocked uh by default. And lastly for um identity parameter uh only trusted identities from within our organization can access our AWS resources. Uh anything uh from outside Vanguard is Vanguard's AWS arg uh is uh blocked by default. And of course there is uh exception handling uh but this is uh the boundary uh that we defined. Uh over to Agnel uh for going over our implementation uh the exception handling and the challenges uh that we had to overcome. Good afternoon everyone. I am Agnel Amodia, technical lead at Vanggard Group. So when we started implementing our defined boundaries using policies, one big question was whether to apply these policies at account level or OU level. O level policies are easier to manage at first, but it it becomes a problems when you need a fine-tuned exceptions for specific teams or accounts. So we chose to apply this policies RCP and SCPs at account level which gave us more control and flexibility. We also kept the OU layer clean so it can be used later on for broader security invariant controls or service enablement controls enforcements. So once the key decisions were made such as defining the policy bound defining the boundary for the organization and applying them at the account level the next big thing was implementing them using policies. But here is the challenge. There is no dry run mode for this policy which means once the policy is applied once the policy is deployed it is immediately effective and it can break the applications without even warning. So we relied on a cloud trail locks to identify how my applications are behaving today and predict what it can break tomorrow. So for resource parameter we built Python scripts to look into the cloud trail events to identify user identity account ID did not match with the recipient account ID field for particular IM user or role and if it is identified for say let's say env from de development environment if an IM user or role is trying to access resources in a production environment we flagged it for a violation so in a nutshell If the resource is not part of our organization, we flagged it for a violation. Similarly, for network parameter, we scanned all API activities to check whether a request made by an IM user or IM role is coming from trusted networks using a source IP address. Then we compare this source IP address with an internal network VPCs and corporate C IP addresses. And if the request is identified coming from outside our organization, we flagged it for violation. So one of the key important decisions we made while rolling out network parameter controls was not to roll out controls for all identities. First focus on rolling out controls for network parameters only on privileged identities such as human identities, you human identities, user identities, application identities and EC2 instance roles. And before implementing network parameter controls for Lambda functions, we built a detective controls to enforce developers to bring their Lambda functions within a VPC and that gave enough time to developers without breaking anything. Similarly for identity parimeter we checked whether if any application outside from our organization is trying to access our resources we considered that resources as an external principle and flagged it for violation in all cases whether it's a resource parameter network parimeter or identity parameter we identified the script we built identify or risky IM identities and risky resources. And this report helped us reach out to the development teams with a clear message that hey here are the resources that may be impacted if we enable RCPS and SCPs tomorrow. And this visibility was really crucial for us because of the smoother rollout and balancing between the business continuity and security without taking down any critical applications. One of the challenges we faced in a data gathering in a from cloud trail was incomplete visibility. Not all API activities were logged in a cloud trail because of the business reasons or service limitations. So if for an example let's say S3 get object calls were not locked in the cloud trail we could not see which IM users or roles are trying to access resources outside our organization. So which means we risk missing critical patterns and if we rolled out controls blindly that could have broken the production applications. So we took a different approach here. We involved developers. We make sure we spread awareness about data parimeter program across the organization and ask development team to review their IM permission policy and resource-based policies. So here are the few conditions key we used while implementing RCP and SCPS. I think pretty much everybody is familiar with this conditions key. So we are not going to go too much detail into it. One of the challenges we faced while rolling out network parameter controls was managing VPC ids and corporate C corporate IP addresses at scale. At first we hardcoded all these values into the SCP and RCPS. But as more VPC ids are added, as more VPC ids are added, policy size grew and we hit AWS limits. And in addition if new VPC ids are created because of the nature of we have hardcoded all these values we have to manually update each and every policy across the organization which is not a practical solutions when you are dealing with hundreds of AWS accounts like we are at Vanguard. So the better solution we deployed we deployed a lambda function that runs in each and every AWS account and this lambda function dynamically fetches all VPC ID and incorporate C blocks and and feeds them into the cloud for template. So we didn't have to hardcode anything but this is not an ideal solution. What if the lambda function fails? If the lambda function fails, policy deployment fails too. And on top of that adding a new every new VPC ID is added we have to redeploy everything. So the better solution if AWS is provided a global condition key such as a VPC or ID that could tell us whether the request is made by an IM user or role is coming from any VPC within my organization. This whole process would be much more simpler, faster and reliable. While designing identity parameter using resource control policies, we used the principal orc path condition key to allow access from trusted organizations identities. And for exceptions, we use resource stack condition key to allow access from external partners at the resource level. But we hit a challenge. Resource tag is not supported on S3 bucket. It only works on individual objects and taggings of millions of objects for thousands of S3 bucket wasn't just a practical solution for us. So we took a coarse grain approach using a principal account condition key. We built our RCP policies. But this is not again our ideal solutions. If AWS could provided a resource tag condition key which can supports the S3 which is available for S3 buckets, we can freely designed the uh fine grain access controls for S3 buckets. So after rolling out controls for RC using SCP and RCP wasn't just an end state for us. We have to make sure everything is working as expected once the controls are rolled out. So first we ask developers to postcertify their applications to test their applications to catch any access denied errors and we built a cloud trail dashboards to identify or to monitor any large spikes in access issues. This give us the real-time visibility into how our policies are behaving. If there is any large spike in access issue which means something is wrong with our policy we rolled it back. We investigate it fix it before reapply fix it before reapplying it. And there is only one IM role or user was affected. We directly work with the client or a developer to add necessary exception tag to the respective resources. This is a really important topic regarding the exception. To manage exceptions properly, we did not rely on a manual tracking. Instead, we built it into our CI/CD pipeline. For an example, a developer includes a external access into their IM permission policy or resourcebased policies, the CI/CD build fails. And to continue, they must log a risk into the risk management system. Once the once it is approved, they can go ahead and apply the data data parameter tag to the respective resources. On top of that, we we run regular queries to identify all IM users or roles or resources with a data parameter tag which has no documented exception. So this report helped us reach out to the development teams to ensure that the exceptions are properly granted, approved and tracked. So here are the few key takeaways we learned from our journey. Start with small. Do not roll out everything at once. Define the trust boundary for your organization at first ahead of time. Get the developers buying first. The more your developers understand data perimeter goals, the smoother your rollout will be. Focus first on identities that carries the most risk. That's where you are going to get the most value out of it. And always be mindful about SCP and RCP size limit and design with scale in mind. Always use a tag based approach. If it is not supported, fall back to the account level exception. And lastly, if something is not supported by AWS, a feature is not supported by AWS, don't wait. Engineer your way forward. We did it at Vanguard and you can too. Thank you so much everyone. Questions from anyone? Amazing talk. Quick question. How do you handle net new AWS accounts that get on boarded to your um organization? You're saying the number of AWS accounts? No. Uh net new net new AWS accounts that get created. I did not get it. Like new AWS accounts that are created of the frequency with which the new AS accounts are created. Yeah. Like how do you go about uh implementing all these controls on new accounts? Is that automated or how how does that look like? It's not automated. Someone has to redeploy uh SAP policies and RC policies manually. So let's say for an example of one is AWS account is created. The SP and RCP policies are not deployed automatically. Someone has to still there is a manual process that has someone has to click a button to deploy this SAP and RCPS. Okay. Yeah. Hey, I was uh wondering how did you guys engage the developers in your organization? Were you manually reaching out or did you have a tool helping you or because you said you had 20,000 employees? Yeah, excellent question because uh couple of mediums we used reaching out to the developers. One is we had a program going on in our organization. Um that program help us to reach out to the each and every line of business of our different teams in the organization. That's a one way. Another way is we hosted office hours to spread awareness about data pyramid program across the organization for a month and more than that. Another way to reach out to the development team is through email communications. We identify all risky IM roles, users, the application that were impacted from the cloud trail. We gather all these inventories and send it out to the development development team through emails. So those are the three key mediums we used reach out to the developers. Hi uh great talk. Um I'm curious how did you implemented that CI/CD checks? Yeah so we use CSPM tool to write all the codes. So whenever a developer pushes any code change the CI/CD tool the CSPM tool checks behind the scenes whether the policy contains any kind of a violations for an example like external as account if it is there then the CI/CD builds fails and to fix that build developer needs to log developer needs to uh document the necessary risk once the risk is approved uh the CI/CD pipeline will check that the risk is already approved then CICD pipeline will uh successful and after that they can developer can go ahead and add the necessary data pyramid attack on the respective resource. We'll take one more. Um what is the process of um logging a new risk into the risk management system look like? Did your team need to approve like all all of those risks and if not um who does? Yeah. So it depends on the organization's ownership and responsibility. We are part of the IM cloud team and we owns all permission boundaries, IM permissions. So if the IM permission policy violation occurs, we are the one who approves review the risk and approve the risk. But let's say if there is an example there is a uh infrastructure control violations that goes to a different team. Thanks everyone. Um I know there's uh some questions in the Slack as well. So please um I encourage everyone to uh pick up the conversation there if there's any more questions. But uh for now thanks for uh talk and uh let's uh give him a round of applause.