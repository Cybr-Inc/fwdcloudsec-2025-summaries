# The Good, The Bad, and The Vulnerable: Breaking Down GCP Tenant Projects

**Video Link**: [Watch on YouTube](https://www.youtube.com/watch?v=WUO_-Agpcxs)

- **Author**: Ofir Balasiano and Ofir Shotti (Palo Alto Networks)
- **Talk Type**: Security

## Summary

This presentation explores GCP tenant projects - hidden projects managed by Google or third-party vendors that run workloads on behalf of consumers. The researchers demonstrate a critical security vulnerability in Vertex AI that allowed them to gain unauthorized access to tenant projects, escalate privileges, and access consumer data across project boundaries. They reveal how these "shadow projects" create an invisible attack surface with significant security implications for cloud environments.

## Key Points

- Tenant projects are GCP projects owned by service producers (Google/vendors) but run consumer workloads and store consumer data
- Many common services use this model: Vertex AI, Cloud Composer, Cloud SQL, BigQuery infrastructure
- Network connectivity occurs through Private Service Connect (PSC) forwarding rules or VPC peering
- Service agents (P4SA accounts) are automatically created with broad permissions across project boundaries
- Researchers found vulnerability in Vertex AI allowing container injection and code execution in tenant projects
- From tenant project access, they achieved privilege escalation to access consumer resources they couldn't normally reach
- Consumer data moves between tenant projects and is stored outside consumer's direct control
- Three types of service accounts operate in tenant projects: service agents, system service accounts, and Google internal groups
- Removing scope restrictions allowed complete takeover of tenant projects with editor-level permissions
- Model weights and training data are copied between multiple tenant projects during AI workflows

## Technical Details

**Tenant Project Architecture:**
- Producer-consumer model where producers manage core services from their GCP organization
- Tenant projects linked to tenancy units representing consumer-service instance relationships
- Two main connectivity patterns: PSC forwarding rules and VPC peering
- Service agents automatically created with cross-project permissions

**Vertex AI Implementation:**
- Creates two tenant projects per consumer: one for training, one for deployment
- Training data moves from consumer project to training tenant project
- Model weights stored in training tenant, then copied to deployment tenant
- Custom container images accepted without validation (vulnerability entry point)

**Service Account Classification:**
- **Service Agents**: Project-specific accounts (e.g., AI Platform CC, Container Engine Robot)
- **System Service Accounts**: Cross-tenant accounts (Training JMS, Service Agent Manager, Pipeline Robot)
- **Google Internal Groups**: "Two Sync" group (observed but not actively operating)

**Vulnerability Chain:**
1. Custom container injection in Vertex AI training jobs
2. Code execution as service agent in tenant project
3. Token extraction and privilege enumeration
4. Access to internal Google repositories using service agent credentials
5. Scope removal leading to editor role assignment
6. Complete tenant project takeover

**Attack Implications:**
- Access to consumer resources without consumer-level permissions
- Privilege escalation beyond intended service boundaries
- Data exfiltration from tenant projects containing consumer data
- Potential cross-tenant access to other customers' resources

**Detection and Monitoring:**
- Audit VPC peering connections and PSC forwarding rules
- Monitor IAM policy bindings for service agents and system accounts
- Use Cloud Audit Logs to trace resource access patterns
- Encrypt sensitive data with CMEK to limit tenant project access
- Scope down data transfers and network rules for tenant connectivity

**Risk Categories:**
- Overprivileged service accounts with excessive cross-project permissions
- Insecure network configurations exposing consumer networks
- Sensitive data storage in unmonitored tenant projects
- Missing operational logs and visibility into tenant project activities
- Inadequate isolation between different consumers' tenant projects

## Full Transcript

Good morning everyone. If you can find your way to your seats, we'll be getting started here in just a moment. Um, before we do that though, I'd like to thank our sponsors who make all this possible. Uh, in particular, our bronze sponsor, Chaser. Uh, if you'd like to learn more about their products and services, you can find their booth out in the vendor hall. Um, if you have any questions throughout the session, uh, we'll be saving those for the end. I'll run around with a microphone and have you ask them. Uh, getting us started now. This is uh the good, the bad, and the vulnerable breaking down GCP tenant projects by Ofir Balasiano and Ofir Shotti. Thanks. Hello everyone. Thank you for joining us today. My name is Ofir Balasiano and with me Oir Shhati. We're both security researchers at Palo Alto Networks and we really wish we could be there with you today in person, but we hope you're having a great time. Anyway, um like many of you, we spend our days looking at cloud environments and asking how does this actually work? Our journey into tenant projects started during Vert.x AI research and today we're going to sh to share a map we made down the tribe hole. Here is our warm up for the next few minutes. First, we'll define the what explaining what tenant projects are and how they are architected. We will see how they can be possibly be connected back to your projects and networks. Then we'll get to the fun part, the vulnerable. We'll walk you step by step through our research into Vert.ex AI, showing how we open up this black box. From there, we'll discuss the border risk this architecture can introduce. And finally, we'll briefly discuss some insights on how can we discover and monitor such tenants. Let's start with fundamental question. What if your sensitive data, your critical workload lives in a GCP project that you don't directly own, manage or even know that exist? This is this is not hypothetical. This is the reality of how many managed services like third party vendors or even Google managed services operate. They spin up tenant projects sometimes called shadow project to to deliver their functionality. The architecture behind it is a classic producer consumer model. The producer, usually Google or third party SAS vendor manages the core service and its control plane from their own GCP project. When you, the consumer, enable or use this service, the producer provisions one or more tenant projects specifically for your instance of that service. The tenant project lives in a produce in the producer organization but but run workloads and connect the billing and and store data on your behalf. The ten the tener projects are linked to a tenency unit which is a resource representing the link between the consumer and the specific instance of that managed service. Now this architecture is not arbitrary right there are some legitimate reasons for it which is the good part from our perspective as the consumer the primary benefit is simplified operations. We get to use powerful and complex services like cloud composer or vert.xai without having to manage the underlying infra. We're effectively outsourcing the operational headache back to the service provider. This also provides stronger isolation. The service running in its own own sandbox project. So its resources usage or potential misconfiguration is less likely to impact our other critical workloads in the production. From the service producer perspective, as the producer, it's all about control and visibility. They get total life cycle management. They can patch, update, and manage their services inside the tener projects. All without needing deep hooks into our projects. This also helps them to get granular water and billing control over their services, backends, and resources. So, which services actually use this model? Many of those you likely use daily in GCP. Vert.ex AI for its managed training. Cloud composer is another classic example. Even cloud SQL and part of BigQuery infra operate using tenant projects managed by Google. So how does the network connectivity between consumer and tenant project work? There are two main mechanism that we observed out there. The first one is creating forward and rules using private service connect or PSC which is a common way these tenant projects connect your VPC network. On the producer side in the internet project they create service attachment and on the consumer side a forward in GR which acts as PSC endpoint into your VPC targeting that service the service attachment that producer created in the tenant project. We will see an example later. Another use case is a classic VPC pairing between the VPC in your consumer project and the VPC in the tenant project. Let's look at a real example from CloudSQL. In CloudSQL, when you create an instance, the VPC has a dedicated pairing to a service networking network. If you click on it, you will see that the target VPC is in a different project that ends with TP, which refers to tenant project. in file store like like cloud cloud SQL is deployed into Google managed VPC in a tenant project and the peering is established within your VPC as you can see here in the red TP again in cloud composer which is a great example of using um the PSC the forwarding rule you can see that there is a PSC endpoint from your uh uh consumer project into a cloud SQL uh DB that resides within a VPC in the tenant project. Another critical critical concept is a service agent. I assume that most of you know about it. Sometimes referred to P4SA per product per project service account. When you enable GCP service, Google automatically creates these special service accounts. Their naming convention often look like this in the green. They are granted roles often quite broad by default within your consumer project to allow the service to function. It's like cross project permissions. Beyond this, as we will see later, the tenant project itself has its own internal service account and we will drill down it later. Here is an example of the service agent that operates with our within our tenant project. uh we'll take a look um on most of them later but we took this list from the cloud cloud audit logs. Another aspect is data movement. Data asset can also be transferred to the tenant project. For example, in Vertx AI we observe that when you spin up a new Vertx AI instance, two different um um tenant projects are created. One from for training, one for deployment. We will again talk about this uh in details later. But what I wanted to say here is that um we saw that data from the consumer project for training data moved to the first tenant and the model weights resides in the second tenant. So these tenant projects contain production consumers data. Okay. So we understand that there is a mysterious project that connected to our project with network IM and data access and very few details publicly documented about it. As security researchers we could not resist. We had to ask what if we could open this black box. This is exactly what happened when we found a bug in Vert.x AI implementation of tenant projects. Our entry point was standard feature. We noticed Vert.x AI custom job. We saw that users can provide their own container image. There is no validation process for its content. We created a container image with a simple reverse shell of course and we could get code execution in the environment where Vertex ran its training jobs. At the moment we got shell, we had our first confirmation. We were not at a consumer project anymore. We were running as GCP SA AI platform CC as you can see here highlighted in red which is a service agent inside Google managed worker. We were inside a tenant project. Next we ran our usual playbook access to IMDS extract token secrets and gathered any information we could get. Once we got our initial access we had some specific research question that we wanted to get answered. First is how does this tenant project actually build? The second one is now that we are in the tenant project can we get priv privilege escalation and get some consumer access to data resources that we didn't have access to in first place. The third the third one is if we if from the tenant project can we get access to internal Google resources. And the last one of course the cloud the crown the the crown jewel is if we from the tenant project can get an can do an impact on projects of other consumers of Google customers. Now will continue with deep dive into the vertex vulnerability we found and actual answers for such questions. Hi there. So with our new initial access, we've started to explore our new tenant project. Start with enumeration, listing resources, reading logs, listing permissions, and we started to build the picture of how Vertex AI operates behind the scenes. Our journey begins with revealing the key actors in the term project. We took a dump of all permissions and we classified the service accounts into three main categories. So far we discussed the service agents which are project dedicated. But we also found out that there are two more types of service accounts. They are not project dedicated and probably has cross tenant privileges. The first is the system service accounts and the second is a a Google internal group uh called two sync. Here is an example for listing the permissions in the ter project. Uh at the top you can see the group uh for two sync and at the middle we see some system service accounts and the last row is the uh service agent. And now that we know who are the authorized entities in the ter project, we want to uh understand what are their responsibilities. So we mapped all the operation in the ter project. And for example here we can see the training JMS system service account and which is responsible for creating the cluster and JMS stands for job management service. So here are the main actors. We saw two service agents that are mapped to our consumer project. The service consumer manager which is responsible for creating the um tenant project and the container edging robot which is responsible for managing the cluster, creating pods and stuff like this. And we saw also three system service accounts. The service agent manager that from its name you can understand what it is responsibility. It's responsible for granting permissions to other service agents. The training JMS which we just talked about uh two slides ago and the pipeline robot which is responsible for setting some permissions and sync management. Also it's worth to mention that the internal Google service accounts the groups uh to sync was not observed operating in the tenant at all. So we talked about listing all resources in the tenant project before but what I'm going to show here is not actually resides inside the tenant project. During the research, we encounter multiple image artifact URIs from the training job pipeline from the data script on the compute that we are running on from the Kubernetes cluster and we found some restricted repositories that we were able to access some of them using the service agent credentials. So the internal images are located in the porta project and were not were not accessible by the uh consumer service account but using the uh service agent in the tenant project we were able to access them. Now to a second example. Um we're able to access consumer resources using the tenant project from the tenant project. While the consumer user we we're operating with doesn't necessarily have permission to access those resources using the service agent we're able to access resources like um cloud storage and bigquery a classic privilege escalation. Now although we were elevated our privileges we couldn't use the full potential of our permissions because the compute we were running on had limited scope a read only like you can see here. So we kept playing with the configuration of the custom job until we finally discovered that if we are using different type of machine it is being created without the scope. Now removing the scope enable us to create another machine with the default editor role and take over the tenant project completely. Another privilege escalation. This is another example for bad backend implementation that may have significant effect on the security structure. Now to a different type of misconfiguration more focused on data. By analyzing the logs uh in the tenant project, we found evidence that data from the consumer project is moved between tenant project. Although there was some segregation, some data like images actually moved between those tenant projects. We also know that the model was trained on one tenant project like mentioned before and deployed on the second project. So when we train AI model its weights the adapter layer which is the result of the training process is being saved on tenant project number one. But when we took over tenant project number two we discovered that those adapter lay this adapter layer actually exists there as well. So it is being copied. So data moved from the customer consumer to the tenant project and also between tenant projects. In the following screenshot you can see the model artifact result the adapter layer. We see here screen from the consumer and it is being saved on the path under the tenant project. This is a consumer data in the tenant project. Also here we can see that when we train the the in the training process we upload the training data set and it is also being copied to the 10 project the path here indicate that. So we talked about the good and the vulnerable. The vertex AI example highlights a specific instance but it points to a broader categories of what can go wrong. The risk the most common issue as we saw it is overprivileged service account but beyond that insecure network configuration like risky VPC peering setups can expose your network. Uh we saw examples for uh VPC pairing in cloud SQL and file store. Sensitive data might be stored within the ten project itself or critical operational logs might never make it back to you. And Vert.Ex is not alone in the playground. Researchers have found and exposed tenant projects in GCP using SQL, Cloud One, Cloud Composer, and more. Now, tenant project may seem isolated, but they often aren't. accepting the fact that things can go wrong. And while the cloud providers put the duty on the customer with the share responsibility model, you may want to be prepared and get a little bit of control into your hands. So 10 projects are not invisible. They are just unmonitored. And this is exactly how attackers like it. This is an entire tax surface that customers are not aware of. Although a simple button of list all tenant project doesn't exist. Here's what you can do to discover what tenant projects are in your environment and what data is being moved there. You can check out the existence of network resources in your environment like VPC pairing and forwarding rules like offir mentioned before and check out IM policy bindings for service agents and system service accounts and maybe the most powerful tool that you can use is the cloud audit logs. You can check for access to cloud resources. Build your own picture to your own environment. Thank you all for listening and I hope you enjoyed the session. Thank you very much. Of uh we have some time now for some questions uh to get us started. We'll take one from Slack. Uh what's the strategy to have tenant project have strict egress? So even when data flow from producer project it doesn't leave the tenant projects. That's a good question. Uh I can take it. Um so tenant projects as we said are not part of our organization. So there's no way to restrict or to um implement some security measures there. But um what you can do is to based on the knowledge we gained uh in this session we can restrict on data uh data flow network and IM. So we can um um scope down the data that transferred from our projects to tenant projects. we can uh create or policies to restrict to restrict uh network rules like PSC or to restrict like specific IM um access to to our sensitive data. So in that way we can make sure that only the data we know that we don't we want to move to projects will be there. Another option is to um is to encrypt our data with CIMC which prevent other um other resources out of the ten project to access this uh this data. Um this is one of the the options. Awesome. Thank you very much. Do we have any questions in the room? Feel free to raise your hand and I can come running over to you. All right. Okay, I think that pretty much covers it. Again, thank you so much. Of Nir, can we get a good round of applause?