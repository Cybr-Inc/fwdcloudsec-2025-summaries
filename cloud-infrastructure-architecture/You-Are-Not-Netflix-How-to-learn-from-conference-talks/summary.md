# You Are Not Netflix: How to learn from conference talks

**Video Link**: [Watch on YouTube](https://www.youtube.com/watch?v=pRrK9PNz2GM)

- **Author**: Rami McCarthy
- **Talk Type**: Professional Development

## Summary

This talk argues that conference presentations often provide an incomplete, idealized, or outdated view of a technical solution or project. The speaker, Ramy McCarthy, advises attendees to be critical consumers of information, to understand their own organization's problems first, and to engage with speakers directly to uncover the missing context, rather than blindly attempting to replicate what they see on stage. The core message is that the "why" behind a project is often more complex than presented and that solutions are not universally applicable.

## Key Points

- Conference talks are often partial truths because speakers want to sound smart, avoid embarrassment, and are bound by organizational or social constraints.
- The full context, including organizational dynamics, technical debt, or business pressures (like M&A or vendor relationships), is frequently omitted.
- Attendees should not blindly copy solutions they see, as they may not be relevant, cost-effective, or suitable for their own environment's scale and architecture (the "You Are Not Netflix" principle).
- Technology and best practices evolve, so a solution presented in a talk from a few years ago might be outdated (e.g., relying on screen-scraping when APIs now exist).
- It's crucial to enter a conference with a clear understanding of your own problems and use the talks as a resource to find solutions, rather than letting the talks dictate your priorities.
- Engage with speakers after their talks to ask clarifying questions and get the "real story" and the context that was left out.
- Speakers are encouraged to be more vulnerable, share the challenges and failures, and provide context about the longevity and actual outcomes of their projects.

## Technical Details

The talk uses several technical projects and concepts as examples to illustrate its points:

- **Architecture Components**:
    - **Netflix's Multicloud Architecture**: Mentioned as a complex system you shouldn't copy. It involves segmenting identity, compute, and data into separate accounts to manage massive scale and data gravity, which is unnecessary for smaller organizations.
    - **CI/CD Systems**: Talks about rolling your own CI/CD are often motivated by distrust of vendors or, conversely, moving back to SaaS because self-hosted solutions (like Jenkins) become security risks.
    - **PKI (Public Key Infrastructure)**: Referenced in the "Yuba disaster" talk, where the solution for break-glass access depended on a sophisticated, pre-existing PKI that most organizations don't have.

- **Technologies and Tools Mentioned**:
    - **AntiP**: A distributed, Lambda-based inventory collection system built by Chris Farris. The talk notes it was created due to specific cost and organizational constraints at the time that may no longer apply.
    - **Yubikeys**: Used in the "Yuba disaster" talk for emergency break-glass access.
    - **Repo Kid**: An older Netflix IAM tool that used to screen-scrape AWS Access Advisor because APIs were not available at the time, highlighting how solutions become dated.
    - **CSPMs (Cloud Security Posture Management)**: Used as an example of the "build vs. buy" dilemma, where talks often don't cover the full decision-making context (e.g., cost, unique architecture, existing data lakes).

- **Specific Methodologies**:
    - **Break-Glass Systems**: Talks often focus on the cool technical implementation without discussing the underlying reasons why frequent privileged access is needed.
    - **Scaling IAM**: A talk by Will and Devon from HashiCorp is cited as a good example because it showed the entire 5-6 year journey, including the bumps and changes in strategy (granular roles, JIT access, intent-based access).
    - **Scaling AppSec**: A talk by Jacob Salassie is praised for showing the full lifecycle of a program, including things that were right at the time but had to be changed later.
    - **STAR Interview Method**: Mentioned as a format that is *not* recommended for conference talks, though providing a small amount of context is encouraged.

## Full Transcript

Good morning, track two. Um, did everybody have a good time last night? Thanks for uh thanks for showing up at 9:00 in the morning on day two. This is always uh an early slot. Uh, please join me in welcoming to the stage Ramy McCarthy uh with his lightning talk, You Are Not Netflix, how to learn from conference talks. Uh, this talk is sponsored by sponsor Red Canary. They're just outside. If you have a minute, uh, take some time to visit the sponsors, collect things from their booth. Nobody wants to mail anything back. Thank you. Okay, you are not Netflix. How to learn from conference talks. Again, thank you to everyone who hosted happy hours last night. For the folks who are still in their hotel rooms watching this uh on recording, um, it's 9:00 a.m., which means we start with audience participation. Uh, this is your fair warning. Um, you will make me look bad. You will hurt my feelings uh if you don't engage. So, um, I'm gonna ask for shows of hands. The hands go up, they stay up. I will let you know when they can go down. Thank you. So, raise your hand if you've given a conference talk. Oh my god, I have too many slides. Okay. Raise your hand if you've written a blog post. I forgot my audience. Yep. Yep. Hands stay up. Uh, hands stay up if you've shared your experience publicly on Twitter, Discord, whatever. Cool. Keep the hands up if you've like always been 100% honest with people. You've given the whole context. You've told the whole truth. Um you either normally lie to people or you're lying to me right now. Uh these uh the work we do publicly as security people has to be really carefully presented, really carefully couched. Um some of this is organizational, some of this is technical, some of this is social, some of this is about risk. Uh and frankly like the thesis for this talk is if public information is always going to be partial. Um for a variety of reasons I'll cover you never get the whole truth the whole context everything you need to know from people's public work. Uh what can we do about it? How can we adjust? How can we prepare ourselves? and how can we handle uh this situation so that we actually bring back value to ourselves, our organizations when we go to conferences like this and see really cool talks and uh attend happy hours. Um so hi I'm Rammy. I'm a security researcher at Whiz. Uh before that I worked other places. Three out of four of my jobs have been through forward clouds. Uh so check out cloud sec forum on Slack. You know go get yourself a new job if you want it. Um I also advise some startups. Uh none of this is super relevant except for the fact that I am a regular attendee of forward cloudtech and that means I get this talk as an opportunity to be a little naval gazy. So I'm going to be doing a lot of referencing people who are going to be glaring at me in this room. I'm going to be doing a lot of talk about forward cloud sec talks. Um and despite all that I want to say that it's kind of funny because this is a conference where I think people try really hard to be more honest, more vulnerable, give more context, be more nuanced. Uh, and so a lot of my my feedback here is uh maybe more relevant for what you're seeing elsewhere than what you'll see here yesterday and today. Um, oh no, Chris, I didn't charge it. Okay, thank you. Chris is setting me up here with this uh clicker. Thank you. Um, so why aren't conference talks truthful? Like if you're just going to accept my premise that people don't share everything they know in a conference talk, they don't give you all the context. Like what are the underlying causes here? Uh well, some of it is you give a conference talk. You would like to be accepted to give conference talks and sometimes you have to really pitch that you did something incredible, innovative. Um or maybe you don't have to, but you feel like you have to. Uh and then when you present, you want to look and sound smart. I'm certainly trying to do that right now. And so like you're really struggling with um anything that uh shines negatively on yourself, on your organization. Um, it's also the fact that like the truth can be embarrassing or risky. Um, like when you're sharing publicly, generally you're bound by contracts. You're supposed to be doing something in service of yourself or your business. And uh, that means often we can't talk about some of the rough edges, whether those are uh, rough edges of um, organizational dynamics or rough edges of the tool we ended up building and why it didn't work. And frankly, the underlying thing is that we only have so much time. And you're never going to download your entire context for a system you built, a problem you solved during a conference talk. So you have to pick and choose what you feel like the important things for the audience to know are. And hopefully people are picking and choosing some of the drawbacks, some of the things that make these talks less applicable to everyone. But that's tough because you want your talk to come across as something that like everyone should attend and learn and know. Um, so I don't want to uh pick too much on any specific talks, although I'll do that later. Um, so these are like contrived examples of what I mean when I say that talks are lying to you. Um, it and like this is not here to like hurt anyone's feelings or sling anyone mud. These are not like I took a talk and removed the name and came up with the example. Uh, that being said, um, I've seen many of these. So like uh talks you see you see someone talking about like a cool break glass system they built at the organization um and they just have a long talk exclusively about that uh and it's not about the fact that like why are you accessing prod right it's not this context of like we needed break glass for reason x y or z um you have like talks about the joys of multicloud like multicloud will solve your resiliency um but often it's about kickbacks and contractual obligations and relationships and uh acquisitions and M&A you have talks that are about a specific tool, right? Like they they bought something really cool and they used it to solve a cool security problem and they're not going to mention like who the intro came from or or like what discount they got. Uh or there's like some really cool technical problem to solve that probably isn't tied to risk. It's tied to like whatever a leader saw in the news the week before. Um so other examples, right? Uh there's a lot of talks about CI/CD. I would love to give one someday. Um, the talks about like rolling your own CI/CD or moving it on prem are often because you're using vendors that you don't trust anymore. Um, or maybe you're going back to SAS because Jenkins keeps ending up on the internet. Um, there are talks where it's like assumed that what they built is cost-effective because they're telling you that this was great and you should build it too, but it's only cost-ffective because of like how they think about cost in their business and actually it was all externalized on some other team or business unit. Um there are talks that reinvent a wheel and you go up after and you're like oh this is so cool had you seen like other GitHub project and you know probably not before they built the thing and they wish they had um and like there are talks that focus on build it is you know we looked at the landscape of vendors and here's a couple reasons why they didn't work for us um and they're not going to tell you all the reasons why they can't use certain vendors but it's not just about these lies like I think these are pretty blatant where people sometimes give these talks knowing that they have to leave something out. I want to share this technical achievement and I can't talk about the why necessarily because it it brings something complicated for my organization. So, it's beyond outright misdirection. And this is where we can get into like a more concrete real examples from friends. Um because even if they're not lying to you, it doesn't mean they should copy them. Like a big takeaway is that I often see people taking conference talks and assuming it's something they should go build. And there are a lot of conference talks especially at uh deeply technical conferences that describe systems that you should not copy um that would make no sense for you wouldn't be cost-effective have predicates you don't have uh and so here's how we come to Netflix right um title of the talk you are not Netflix because we all want to get accepted to conferences and name dropping helps um but this is a really cool set of work from folks who may or may not be in the room sorry uh around Netflix's multicloud architecture and so I think a lot of folks at this conference may have seen that Netflix has um a really cool model they've like presented a lot with AWS about where you segment out um identity into one account and compute into a different account and you can have your data living somewhere else and like this is very cool. I think if you asked them they would not tell you to go and build it. It is not cool for you. It is cool for them. They have to do it. You don't. Um they have 10 years of data gravity. They have enormous enormous numbers of resources that start to blow out account service limits. They have systems that are already in place and they have to live with and so they have to make these complicated, challenging, innovative choices and you are not always complicated, challenging or innovative. Like if you are in three AWS accounts with your one SAS product, you're probably fine. Um, and you probably have architectural patterns open to you that they no longer do. And here's where we come to Chris, uh, who's an organizer of this conference and, uh, AntiP, which I just pronounced right. Um, excellent. So, AntiP is a a thing Chris shipped that I thought was super cool. Um, it's a distributed system that uses effectively a whole bunch of lambdas to collect inventory information. Um, centralize that data uh and make it operational, right? Very cool. We all have distributed data. We all have distributed systems. Um but like he also has given there's a blog post on this doesn't mention all these drawbacks and reasons but like the reasons they built this at the time were cost considerations were because they have a huge distributed organization was because uh you know they had a bunch of requirements that you probably don't have and so you going and rolling this sort of distributed lambda based inventory system um isn't necessary in 2025 like there are better products there are cheaper products from the first parties from the third parties. Uh there are open- source options, there are better patterns and and so like you can rediscover talks and forget that many things have changed. It can be really hard to figure out like what predicates are crucially important that you need to uh doublech checkck, right? Like you need to revisit an example from forward clouds last year. Yuba disaster super cool talk, super cool engineering achievement. Um Yuba keys for emergency break glass access. Uh, and I was watching this talk and this example means one of two things. It means that um, either this was a talk that did the draw the rest of the owl thing where they talk about using Ubi keys for break glass access and then they point to an open source product that does all the like PKI bits that had already been set up that you have to build on. Um so either it's like this talk is great but step one is a whole lot of sophisticated uh infrastructure at your organization and if you don't have it you can't easily do yuba disaster or it means I don't understand PKI and this is easier that looks and like these are both valid so like what do you do when you're watching a conference talk like what are the questions that should be running through your mind so you can try and catch some of these traps and like you know read between the lines well the first one we talked about like it's not 2018 anymore. Is this still relevant? Uh Netflix uh when they built Repo Kid, which is an IM tool, they had Arvar, which basically screen scraped access advisor. Access adviser has APIs now. This is not relevant to you. Um are there organizational dynamics like this is a big one with cool technical build talks. You often see that they allied the fact that like buying was not an option for some reason that is not um sort of uh about the best choice for the business. It's about um whether people feel like buy is always worse than build, whether we're an engineering culture, whether we have extra headcount that we might as well use, right? There are all these reasons why you can go do a build project and a lot of those reasons aren't going to make it into the talk. A big thing that gets me is that um a lot of the time these talks have an inciting problem, right? It's like you come up on stage like I'm giving this talk because I keep watching people try and copy conference talks that are not relevant to them. There's an inciting problem I'm trying to solve. You may not have that same problem. Um and this is a like brand new idea I've had that totally, you know, hasn't been floating in the ether um and doesn't have this 2014 example from Dave Shackleford about rethinking the security con. Um this is a great blog post. I love when I can dig up something from like a decade ago that uh is relevant to what I'm talking about. Uh you go to conferences and you hear about really cool systems being built, really cool problems being solved and your organization really should be worrying about your public S3 buckets, right? Like just you need to walk in knowing what your risks are and walk out without changing your mind uh just based on new shiny. Uh another big problem with with talks and security is that we're bad at statistics. I mean, everyone's bad at statistics, but in security, you often give a conference talk where it's, you know, there's some data presented, there's some anecdot pulled from somewhere. This is a really good talk, myths and lies in infosc, uh, that dives into some of the really common bad numbers you see bandied around. And so, like, when you're watching a talk, if someone says, uh, 66% of cloud instance are caused by leaked IM keys, right? Like, where are they getting that stat? Is it from the AWS report? Is it from, uh, internal data? Is it based on the fact that they looked at news reports from the past year, right? Like where are these numbers coming from and how much should you trust them? And there's like what I think of as a marketing substance matrix. Um I have no problem being marketed to through conference talks, right? Like uh if it's 10% marketing and 50% something super cool, I'm all in. But you have to stop and think about like what percent of this is marketing, what percent of this is, uh meant to be useful to you. Um, sponsor talks are often like maybe a little bit of a yellow flag where uh that's a sign they didn't have to go through a CFP process necessarily. And another thing is a lot of talks just like focus right down there a paved road of what they did and why they did it and they don't talk about alternatives or they talk about alternatives within the build by adopt framework only. So like um we compared this open source tool to three others and here's why we picked it does not address whether they should have just bought a solution there or built something from scratch. Um CSPMs are a great example. Like some folks have talked about buying a CSPM and they don't talk about whether open source ones would do. Some folks have talked about building their own and they don't talk about like whether it was cost considerations or unique architecture um or the fact that they are a company that already has a data lake with all of this in there and like what does the talk show you? A lot of security talks just show you something they built or a program they developed at their company and they don't talk about the actual process to get there and especially they don't talk about the outcomes. So you have these security talks that pitch you something and if you went and implemented it, what do you end up with? You end up with a whole bunch more findings and some sort of issue tracker. And does that move the needle? I think also like a big thing to call out and something I'm guilty of uh is that you give a talk like when it's fresh in your mind, when you have something to uh interesting you've done and want to share, you don't want to wait three years to see if this system you built was useful or not, right? You just are excited you did it. Um and so uh again great statistics here sources uh I just feel this way but um like people often give these talks about really complicated systems that would be amazing if in 5 years they have shown value and been expanded on and then they leave the company in a year and no one internally can support it and uh by goes the system and they end up buying something. So, I want to call out what good looks like, right? Like, we don't want to be exclusively negative here. A lot of people do a really good job coming into conference talks and trying to um cover a little more of this context and color, whether it's organizational, whether it's things they've done wrong. Uh so, one is from um Will and Devon from Hashi Corp. They give the talk on uh the journey of scaling IM in a a SAS company over five or six years, right? all the decisions you make at a moment in time that are right like we're going to do granular roles, we're going to do absolutely privilege, okay, we're going to roll back and we're going to do just in time access, we're going to do resource-based access, we're going to do intent based access, right? They give the talk that shows the bumps along the way. Um, and then Jacob Salassie talks about scaling an appsac program in a similar way where he talks about like the life cycle of building a partnership program and all the things they did that were right at the time but he stuck around long enough to have to change. And so like the difference between folks who um talk about a moment in time is you really have to extrapolate out and decide whether you think this will will still be useful in a couple years whether it will show value uh or not. So like what do we do about this? Um okay like uh awareness of the problem is always the first step. I think just begging you all to come into talks with a problem to solve of your own instead of assuming that the problem is universal. Um thinking about what context you should pull out. Uh those are like okay light vibe based advice but um there's some concrete stuff right like beyond going in with your eyes open um know your problems seek solutions especially forward clouds like this is why I find this such a good audience is because there are what 40 talks at forward clouds and if you just go and treat it as a buffet of things to bring back to your security team you're going to be sending them like a mix of cool vones and uh issues in OCI and complicated PKI based implementations for multicloud Right? And if you didn't come to Forward Cloud sec with those problems, you're not adding a ton of value. You're not getting as much as you would as if you came here with some specific concerns on AM or some specific concerns on scaling multicloud. Um, and then use talks as a resource to answer your questions. Don't just let the talks lead you by the nose. Um, connect with speakers personally like all conferences, but especially conferences like this. Um, you know, write your list of questions about like, hey, did you guys really do a build versus buy here? Did you just have to build this for some reason? Hey, like, uh, you talk about this working with engineers system. How'd that go in practice? Um, like, hey, I just checked and this open source project is deprecated on GitHub. Is it still relevant? Right? Like, get in the details. Ask questions. People are generally happy to answer. The thing with me like calling all speakers white liars is like uh they don't want to hurt you. Like this is not people being bad actors. They just are hoping that you come ask them that question that they can then give you the context you need. Um like the number of conversations at Ford Cloudtech I've had where someone builds a cool system and I get three or four pieces of information that help me implement it or help me understand it's not for me um is like every talk I've ever taken back to uh my company. And then of course this is Ford Cloudac. It's a practitioner conference. Um but it's also a conference where we're all here to participate. You all raised your hands. You're already giving talks. Give talks. Give better talks. Be a little more vulnerable. Be willing to talk about some of the challenges. Think about if there's something you can talk about that's been cooking for four years. Um instead of like just whatever the new shiny you built is. uh and be really willing to um take that risk of uh you know maybe over a happy hour, maybe uh after your talk in the side hallway um telling people the real details because security is really hard and it gets harder when we tell each other to like build complicated systems or um do things that don't work because we're trying to relearn the same lessons over and over again. So that's all I've got. Um looking forward to uh hearing feedback about context I should provide for my talk afterwards. If you want more from me, whiz blog has a bunch of stuff. Um these slides are live already on speaker deck. So that link has all the slides if people need to click links. And thank you. So we have a few minutes for questions. I'll run a mic to you. Thanks, Ramy. Uh, I'm curious what advice you have. What advice you have for conference organizers that either post guidelines for CFPs or review CFPs? Yeah, that's a great question. So, it depends on the conference. Conferences have different goals. Like forward clouds is designed as a practitioner conference that brings you things back that are actionable. AWS reinvent or reinforce, right, is designed to show you what new is coming from a vendor. Um, and then you have conferences that are about giving people an opportunity to learn and connect. So, it depends on the conference. For a conference like this, I think that it's really imperative that as we develop these talks, as we coach people through giving these talks, we sort of push them to give a little more of that context because the talks here are often diving right into the technical details. We're skipping the 101, but what we're also skipping often is the why. Um, like the why will be a technical problem instead of an organizational context. So I think like during CFPs, uh there's a thing with CFPs where you always should like give a really robust outline. If you want to get accepted, it helps a lot because they can trust that you don't just have an idea, you have a talk track. Um and I think asking as part of that for folks to be a little more thoughtful about like who this is useful for. It's it's a common question on a CFP. They say like who will this talk be relevant for? And you say like intermediate cloud practitioners and like don't do that. like ask more specific questions about like what problem you solved with this talk if it's in a tool track or um you know how long this program's been running or uh you know what we can learn. Um and that being said, I think it's much more about uh building a community where that's the norm because you do have to have a lot of trust in the audience if you're going to uh expose your back like that and say, "Look, I'm going to show you something and by the way, we tore it down six months later." And I still think we can learn from that. other questions. So, um, two things here. So, I I think like people, uh, since it's a practitioners conference, like they don't want to give the context, they feel like they want to dive right into the technical solution. And so, um, what's your thoughts on bringing the STAR interview method to conference talks? Uh, I wouldn't bring the STAR interview method. I think that that's probably too much depth, but like I think even if you only take 1% of your talk time like uh there was this slide from Chris. Chris has a blog post for uh Antiip and the blog post does not mention any of these reasons why they built it, right? And like you can put one slide that says here's a few things you should know about me and my company um before you give me the technical solution. Uh and you can also see at the end here's a few questions you should ask me after the talk, right? like um ask me about the uh engineering effort to build this. Ask me about the cost of this, right? Things you can't say live or on record, but you're happy to discuss more. Kind of going off of that question, I'm a newer speaker. Would you ever propose like a nice outline that we could follow to help make better conference talks like when we're creating our You know, if I had thought of that, that would be a great inclusion in a talk like this. Um you should give that talk. Uh someone should bring that back. No, I think it is really though um about uh that that one slide of why we built the system when you're building a system or why we built this program when you're building a program, right? Not all problems are solved with technical systems. Um, and I think it's also um about stopping and like asking yourself the questions I outlined and and like making sure you know the answers and whether they really deserve to be included because I think people should really stop and think. If you built a system exclusively be due to budgetary constraints, you should be very careful about how you advocate for other people to build that system because you get these bombastic advertisements for like go build your own CSPM that um just lead people down the wrong road when you internally are really unhappy with the consequences of your actions. I'll ask a question which is uh how often do you see that a presentation drifts very very far away from the abstract that was submitted to the conference and what advice do you have for new speakers on how to make sure they deliver on their promise for talks? Yeah, so no one trusts me with a CFP review. So I actually uh I can only assume when I see the abstract announcement and then I see the talk that maybe some drift has happened. I think the big thing for me is um I actually have uh open sourced on my personal website a bunch of the CFPs I've sent into conferences and if you go look you'll see that I write incredibly in-depth outlines. Like I don't submit to a conference until I have most of the talk track and then of course I spend a ton of time on the slides later and and polishing the narrative. But I think that if you are a speaker who's concerned about that risk, if you are a newer speaker, um you can assume that like everyone just sends in their abstract and their title and they don't. People put in a lot of thought to trying to outline their whole talk and what um you know what the takeaways will be, what some of the key references are. And so I think the more you pull that forward into your CFP, the more you're derisking, disappointing your audience. And I think for me that's a huge thing. like maybe it's the imposttor syndrome, but whenever I'm giving a talk, I want to give them everything possible to turn it down if it's wrong for the audience or they're not excited about it. Like I don't want to get accepted to a talk that's going to go poorly. I want to get accepted to talks that people will enjoy. Um, so I think that like you can derisk that by pulling stuff forward into the CFP. Um, and you can also go back and like compare notes, but sometimes things change and you have to just roll with it. All right. Well, it looks like there's no more questions, so give one more round of applause for Ramy.
